{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Index Generation\n",
    "Generates indices for train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import h5py\n",
    "from collections import Counter\n",
    "from progressbar import *\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib\n",
    "#from watchmal.testing.repeating_classifier_training_utils import *\n",
    "from functools import reduce\n",
    "\n",
    "# Add the path to the parent directory to augment search for module\n",
    "par_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if par_dir not in sys.path:\n",
    "    sys.path.append(par_dir)\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "#from testing.repeating_classifier_training import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['angles', 'energies', 'event_hits_index', 'event_ids', 'hit_charge', 'hit_pmt', 'hit_time', 'labels', 'positions', 'root_files', 'veto', 'veto2']>\n"
     ]
    }
   ],
   "source": [
    "# Import test events from h5 file\n",
    "original_data_path = \"/fast_scratch/WatChMaL/data/IWCD_mPMT_Short_emg_E0to1000MeV_digihits.h5\"\n",
    "f = h5py.File(original_data_path, \"r\")\n",
    "\n",
    "print(f.keys())\n",
    "\n",
    "labels     = np.array(f['labels'])\n",
    "root_files = np.array(f['root_files'])\n",
    "\n",
    "veto = np.array(f['veto'])\n",
    "veto2 = np.array(f['veto2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up indices\n",
    "indices = np.array(range(len(labels)))\n",
    "# Set up root file set\n",
    "root_file_set = list(set(root_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter indices based on vetos\n",
    "#overall_veto = np.logical_or(veto, veto2)\n",
    "overall_veto = veto\n",
    "\n",
    "filtered_indices    = indices[np.invert(overall_veto)]\n",
    "filtered_labels     = labels[np.invert(overall_veto)]\n",
    "filtered_root_files = root_files[np.invert(overall_veto)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict set\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Set up dict of file indices\n",
    "file_dict = {}\n",
    "for file in root_file_set:\n",
    "    file_dict[file] = []\n",
    "print(\"Dict set\")\n",
    "\n",
    "for idx, root_file in zip(filtered_indices, filtered_root_files):\n",
    "    file_dict[root_file].append(idx)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "1000\n",
      "3000\n"
     ]
    }
   ],
   "source": [
    "# Get files associated with each particle type\n",
    "gamma_indices       = filtered_indices[np.where(filtered_labels == 0)]\n",
    "gamma_root_file_set = list(set(root_files[gamma_indices]))\n",
    "\n",
    "e_indices           = filtered_indices[np.where(filtered_labels == 1)]\n",
    "e_root_file_set     = list(set(root_files[e_indices]))\n",
    "\n",
    "mu_indices          = filtered_indices[np.where(filtered_labels == 2)]\n",
    "mu_root_file_set    = list(set(root_files[mu_indices]))\n",
    "\n",
    "print(len(e_root_file_set))\n",
    "print(len(mu_root_file_set))\n",
    "print(len(gamma_root_file_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define indices retrieval function\n",
    "def get_indices_for_files(file_names):\n",
    "    all_indices = []\n",
    "    for file_name in file_names:\n",
    "        all_indices.extend(file_dict[file_name])\n",
    "    return np.array(all_indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7868464 7868465 7868466 ... 6296627 6296628 6296630]\n"
     ]
    }
   ],
   "source": [
    "mu_test_files, mu_val_files, mu_train_files = mu_root_file_set[0:400], mu_root_file_set[400:500], mu_root_file_set[500:]\n",
    "\n",
    "mu_test_set, mu_val_set, mu_train_set = get_indices_for_files(mu_test_files), get_indices_for_files(mu_val_files), get_indices_for_files(mu_train_files)\n",
    "\n",
    "print(mu_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3807871  3807872  3807873 ... 17530030 17530031 17530032]\n"
     ]
    }
   ],
   "source": [
    "gamma_test_files, gamma_val_files, gamma_train_files = gamma_root_file_set[0:400], gamma_root_file_set[400:500], gamma_root_file_set[500:1000]\n",
    "\n",
    "gamma_test_set, gamma_val_set, gamma_train_set = get_indices_for_files(gamma_test_files), get_indices_for_files(gamma_val_files), get_indices_for_files(gamma_train_files)\n",
    "\n",
    "print(gamma_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10463637 10463638 10463639 ... 10113221 10113222 10113223]\n"
     ]
    }
   ],
   "source": [
    "e_test_files, e_val_files, e_train_files = e_root_file_set[0:400], e_root_file_set[400:500], e_root_file_set[500:1000]\n",
    "\n",
    "e_test_set, e_val_set, e_train_set = get_indices_for_files(e_test_files), get_indices_for_files(e_val_files), get_indices_for_files(e_train_files)\n",
    "\n",
    "print(e_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(mu_train_files))\n",
    "print(len(e_train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1}\n",
      "{0}\n",
      "{2}\n"
     ]
    }
   ],
   "source": [
    "# Verify that indices match\n",
    "all_e_indices = np.concatenate((e_test_set, e_val_set, e_train_set))\n",
    "print(set(labels[all_e_indices]))\n",
    "\n",
    "all_gamma_indices = np.concatenate((gamma_test_set, gamma_val_set, gamma_train_set))\n",
    "print(set(labels[all_gamma_indices]))\n",
    "\n",
    "all_mu_indices = np.concatenate((mu_test_set, mu_val_set, mu_train_set))\n",
    "print(set(labels[all_mu_indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20613195\n",
      "6889876\n",
      "6889876\n"
     ]
    }
   ],
   "source": [
    "# Verify that all events are uniquely accounted for\n",
    "all_collected_indices = np.concatenate((e_test_set, e_val_set, e_train_set, gamma_test_set, gamma_val_set, gamma_train_set, mu_test_set, mu_val_set, mu_train_set))\n",
    "\n",
    "print(len(labels))\n",
    "print(len(all_collected_indices))\n",
    "print(len(set(all_collected_indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idxs = np.concatenate((e_train_set, mu_train_set, gamma_train_set))\n",
    "val_idxs   = np.concatenate((e_val_set, mu_val_set, gamma_val_set))\n",
    "test_idxs  = np.concatenate((e_test_set, mu_test_set, gamma_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('IWCD_mPMT_Short_3M_OD_veto_idxs.npz', train_idxs=train_idxs, val_idxs=val_idxs, test_idxs=test_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
